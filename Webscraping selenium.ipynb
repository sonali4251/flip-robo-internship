{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8da00cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\user4\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: idna in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user4\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf3686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException , NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4983bd",
   "metadata": {},
   "source": [
    "#Download the webdriver with link https://chromedriver.chromium.org/downloads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19814f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1395f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the driver....methos-1\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\User4\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7475f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\User4\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "601f305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method-2 to connect is go to jupiter notebook homepage upload the package by clicking on upload icon\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92364718",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28fa314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openig the naukari page on automated chrome browser\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "846720cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and loaction as required in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce8da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec526e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f833cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "Experience_required=[]\n",
    "\n",
    "#scraping job title from given wabpage\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping job location from given wabpage\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping job company name from given wabpage\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping experience required from given wabpage\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    Experience_required.append(experience)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2854f751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location),len(company_name),len(Experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c11eca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a544eeda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst | Neiman Marcus Group</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Talent500</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Management Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>1-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Analyst - Data Management</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr Data Analyst - Tableau</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>S.A.W IT Services Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Project Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>WSP</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   job_title         job_location  \\\n",
       "0                               Data Analyst  Bangalore/Bengaluru   \n",
       "1                               Data Analyst  Bangalore/Bengaluru   \n",
       "2                           Sr. Data Analyst  Bangalore/Bengaluru   \n",
       "3  Senior Data Analyst | Neiman Marcus Group  Bangalore/Bengaluru   \n",
       "4                     Senior Data Analyst II  Bangalore/Bengaluru   \n",
       "5             Senior Data Management Analyst  Bangalore/Bengaluru   \n",
       "6           Senior Analyst - Data Management  Bangalore/Bengaluru   \n",
       "7                               Data Analyst  Bangalore/Bengaluru   \n",
       "8                  Sr Data Analyst - Tableau  Bangalore/Bengaluru   \n",
       "9                       Project Data Analyst  Bangalore/Bengaluru   \n",
       "\n",
       "                                     company_name Experience_required  \n",
       "0                                             ANZ             1-4 Yrs  \n",
       "1                                             ANZ             1-5 Yrs  \n",
       "2  MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED             5-8 Yrs  \n",
       "3                                       Talent500            6-11 Yrs  \n",
       "4                                        Flipkart             2-4 Yrs  \n",
       "5                                     Wells Fargo            1-12 Yrs  \n",
       "6                                       Accenture             5-8 Yrs  \n",
       "7  MM STAFFING CAREER CONSULTANTS PRIVATE LIMITED             5-7 Yrs  \n",
       "8                       S.A.W IT Services Pvt Ltd             2-5 Yrs  \n",
       "9                                             WSP             0-4 Yrs  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'job_title':job_title,'job_location':job_location,'company_name':company_name,'Experience_required':Experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e821ddcd",
   "metadata": {},
   "source": [
    "# Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37fc1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and loaction as required in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ae496",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19086904",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d922cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "Experience_required=[]\n",
    "\n",
    "#scraping job title from given wabpage\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping job location from given wabpage\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping job company name from given wabpage\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping experience required from given wabpage\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    Experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e158ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location),len(company_name),len(Experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7246bf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Tata Nexarc</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Nagpur, Pune</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / AI-ML Engineer</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manager-Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - Data Scientist - 09</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...</td>\n",
       "      <td>Mindtree</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>Bangalore/Bengaluru, India, Mumbai (All Areas)</td>\n",
       "      <td>Bizongo</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_title  \\\n",
       "0                  Analystics & Modeling Specialist   \n",
       "1                                    Data Scientist   \n",
       "2                                    Data Scientist   \n",
       "3                   Data Scientist / AI-ML Engineer   \n",
       "4                              Manager-Data Science   \n",
       "5  ACN - Applied Intelligence - Data Scientist - 09   \n",
       "6                                    Data Scientist   \n",
       "7                               Data Scientist - II   \n",
       "8                             Senior Data Scientist   \n",
       "9                Data Science - Engineering Manager   \n",
       "\n",
       "                                        job_location      company_name  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...         Accenture   \n",
       "1  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...       Tata Nexarc   \n",
       "2                  Bangalore/Bengaluru, Nagpur, Pune     Tech Mahindra   \n",
       "3                                Bangalore/Bengaluru      Hitachi Ltd.   \n",
       "4                                Bangalore/Bengaluru  AMERICAN EXPRESS   \n",
       "5                                Bangalore/Bengaluru         Accenture   \n",
       "6  Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...          Mindtree   \n",
       "7     Bangalore/Bengaluru, India, Mumbai (All Areas)           Bizongo   \n",
       "8                        Bangalore/Bengaluru, Mumbai      Baker Hughes   \n",
       "9                     Bangalore/Bengaluru, New Delhi             Paytm   \n",
       "\n",
       "  Experience_required  \n",
       "0             6-8 Yrs  \n",
       "1             4-8 Yrs  \n",
       "2             5-8 Yrs  \n",
       "3             3-7 Yrs  \n",
       "4             3-4 Yrs  \n",
       "5             2-6 Yrs  \n",
       "6            5-10 Yrs  \n",
       "7             3-6 Yrs  \n",
       "8             6-8 Yrs  \n",
       "9             3-5 Yrs  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'job_title':job_title,'job_location':job_location,'company_name':company_name,'Experience_required':Experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd5c93f",
   "metadata": {},
   "source": [
    "# Q3 # Scrape data using the filters available on the webpage:“Data Scientist”,scrape the job-title, job-location, company name, experience required.location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5456c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and loaction as required in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42f3df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "Experience_required=[]\n",
    "\n",
    "#scraping job title from given wabpage\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping job location from given wabpage\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping job company name from given wabpage\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping experience required from given wabpage\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    Experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "685b0bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location),len(company_name),len(Experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bb61301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artificial Intelligence/Computer Vision Engine...</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Vicara</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Activation Specialist - Adobe Target</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Temp. WFH - Noida</td>\n",
       "      <td>NGI Ventures</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Opening For Jr. Data Scientist with Tatras Dat...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Tatras Data Services</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...</td>\n",
       "      <td>torcai digital media</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Americana Restaurants (india)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>URGENT: Data Scientist | Gurugram | 5 Days Wor...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Digilytics</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Alliance Recruitment Agency</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SE/SSE-Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Bold Technology Systems</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Artificial Intelligence/Computer Vision Engine...   \n",
       "1          Data Activation Specialist - Adobe Target   \n",
       "2                                     Data Scientist   \n",
       "3                  Data Scientist - Engine Algorithm   \n",
       "4  Opening For Jr. Data Scientist with Tatras Dat...   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7  URGENT: Data Scientist | Gurugram | 5 Days Wor...   \n",
       "8                                     Data Scientist   \n",
       "9                              SE/SSE-Data Scientist   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "1  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "2                                  Temp. WFH - Noida   \n",
       "3  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "4                                        Delhi / NCR   \n",
       "5  Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                   Gurgaon/Gurugram   \n",
       "8                                              Noida   \n",
       "9                                        Delhi / NCR   \n",
       "\n",
       "                    company_name Experience_required  \n",
       "0                         Vicara             1-3 Yrs  \n",
       "1                 Okda Solutions            7-10 Yrs  \n",
       "2                   NGI Ventures             1-5 Yrs  \n",
       "3                   Primo Hiring             1-3 Yrs  \n",
       "4           Tatras Data Services             2-4 Yrs  \n",
       "5           torcai digital media             2-7 Yrs  \n",
       "6  Americana Restaurants (india)             3-8 Yrs  \n",
       "7                     Digilytics             2-5 Yrs  \n",
       "8    Alliance Recruitment Agency             3-4 Yrs  \n",
       "9        Bold Technology Systems             3-8 Yrs  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'job_title':job_title,'job_location':job_location,'company_name':company_name,'Experience_required':Experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c6c7c",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:Brand, ProductDescription\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1ba0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the driver....methos-1\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\User4\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ff06f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c00c5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbe0be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty lists\n",
    "Product_Brand=[]\n",
    "Product_Description=[]\n",
    "Product_Price=[]\n",
    "Product_Discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37ab19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping the brand of sunglasses \n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:40]:\n",
    "    brand=i.text\n",
    "    Product_Brand.append(brand)\n",
    "#scraping product description from given wabpage\n",
    "\n",
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in product_tags[0:40]:\n",
    "    product=i.text\n",
    "    Product_Description.append(product)    \n",
    "#scraping price from given wabpage      \n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:40]:\n",
    "    price=i.text\n",
    "    Product_Price.append(price)    \n",
    "#scraping discount from given wabpage  \n",
    "discount_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "for i in discount_tags[0:10]:\n",
    "    discount=i.text\n",
    "    Product_Discount.append(discount)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3a63c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Product_Brand),len(Product_Description),len(Product_Price),len(Product_Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a26a8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping the brand of sunglasses \n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:100]:\n",
    "    brand=i.text\n",
    "    Product_Brand.append(brand)\n",
    "\n",
    "#scraping product description from given wabpage\n",
    "\n",
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in product_tags[0:100]:\n",
    "    product=i.text\n",
    "    Product_Description.append(product)\n",
    "\n",
    "#scraping price from given wabpage      \n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:100]:\n",
    "    price=i.text\n",
    "    Product_Price.append(price)\n",
    "\n",
    "#scraping discount from given wabpage  \n",
    "discount_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "for i in discount_tags[0:100]:\n",
    "    discount=i.text\n",
    "    Product_Discount.append(discount)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f14bfb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 160 160 130\n"
     ]
    }
   ],
   "source": [
    "print(len(Product_Brand),len(Product_Description),len(Product_Price),len(Product_Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79679a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Product_Price</th>\n",
       "      <th>Product_Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Rectangul...</td>\n",
       "      <td>₹849</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (53)</td>\n",
       "      <td>₹278</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "      <td>₹129</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹149</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (53)</td>\n",
       "      <td>₹129</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹286</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹749</td>\n",
       "      <td>90% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹949</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection, Polarized Rectangular Sunglasse...</td>\n",
       "      <td>₹129</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹539</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Product_Brand                                Product_Description  \\\n",
       "0   VINCENT CHASE  by Lenskart Polarized, UV Protection Rectangul...   \n",
       "1    Silver Kartz           UV Protection Clubmaster Sunglasses (53)   \n",
       "2      LIZA ANGEL  Riding Glasses, Night Vision Spectacle Sunglas...   \n",
       "3       Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...   \n",
       "4      PHENOMENAL         UV Protection Retro Square Sunglasses (53)   \n",
       "..            ...                                                ...   \n",
       "95      Elligator                UV Protection Round Sunglasses (54)   \n",
       "96  VINCENT CHASE  by Lenskart Polarized, UV Protection Wayfarer ...   \n",
       "97  VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "98     LIZA ANGEL  UV Protection, Polarized Rectangular Sunglasse...   \n",
       "99       Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...   \n",
       "\n",
       "   Product_Price Product_Discount  \n",
       "0           ₹849          57% off  \n",
       "1           ₹278          81% off  \n",
       "2           ₹129          87% off  \n",
       "3           ₹149          75% off  \n",
       "4           ₹129          87% off  \n",
       "..           ...              ...  \n",
       "95          ₹286          85% off  \n",
       "96          ₹749          90% off  \n",
       "97          ₹949          75% off  \n",
       "98          ₹129          87% off  \n",
       "99          ₹539          85% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Product_Brand':Product_Brand[0:100],'Product_Description': Product_Description[0:100],'Product_Price':Product_Price[0:100],'Product_Discount':Product_Discount[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7aa34e",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\n",
    "place=FLIPKART\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f82c5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the driver....methos-1\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\User4\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3900b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c15fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44c2c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "Product_Rating=[]\n",
    "Review_Summary=[]\n",
    "Full_Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6fdd35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping rating of the product\n",
    "rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags[0:100]:\n",
    "    rating=i.text\n",
    "    Product_Rating.append(rating)\n",
    "    \n",
    "# scrapping review summary of the product    \n",
    "review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in review_tags[0:100]:\n",
    "    review=i.text\n",
    "    Review_Summary.append(review)\n",
    "\n",
    "# scrapping full review of the product  \n",
    "fullreview_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in fullreview_tags[0:100]:\n",
    "    fullreview=i.text\n",
    "    Full_Review.append(fullreview)\n",
    "    \n",
    "#Nevigating to the next page\n",
    "next_page=driver.find_element(By.XPATH,'//a[@class=\"ge-49M\"]')\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e801df7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 160 150\n"
     ]
    }
   ],
   "source": [
    "print(len(Product_Rating),len(Review_Summary),len(Full_Review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a667c732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Rating</th>\n",
       "      <th>Review_Summary</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Best and amazing product.....phone looks so pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Value for money\\n5 star rating\\nExcellent came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>I was using Iphone 6s and also Oneplus 6t. Bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_Rating       Review_Summary  \\\n",
       "0               5     Perfect product!   \n",
       "1               5  Best in the market!   \n",
       "2               4      Value-for-money   \n",
       "3               5    Worth every penny   \n",
       "4               5   Highly recommended   \n",
       "..            ...                  ...   \n",
       "95              5   Highly recommended   \n",
       "96              5   Highly recommended   \n",
       "97              4     Perfect product!   \n",
       "98              5   Highly recommended   \n",
       "99              5       Simply awesome   \n",
       "\n",
       "                                          Full_Review  \n",
       "0   Best and amazing product.....phone looks so pr...  \n",
       "1   i11 is worthy to buy, too much happy with the ...  \n",
       "2   It’s a must buy who is looking for an upgrade ...  \n",
       "3   So far it’s been an AMAZING experience coming ...  \n",
       "4   Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "..                                                ...  \n",
       "95  What a camera .....just awesome ..you can feel...  \n",
       "96  Value for money\\n5 star rating\\nExcellent came...  \n",
       "97  I was using Iphone 6s and also Oneplus 6t. Bot...  \n",
       "98  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "99  This is my first iOS phone. I am very happy wi...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Product_Rating':Product_Rating[31:131],'Review_Summary': Review_Summary[31:131],'Full_Review':Full_Review[31:131]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9473a058",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "33458e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the driver....methos-1\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\User4\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6e64fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "31bd2502",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6aa6127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty lists\n",
    "Sneaker_Brand=[]\n",
    "Sneaker_Description=[]\n",
    "Sneaker_Price=[]\n",
    "Sneaker_Discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4f781b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping the brand of sneaker\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:40]:\n",
    "    brand=i.text\n",
    "    Sneaker_Brand.append(brand)\n",
    "#scraping product description from given wabpage\n",
    "\n",
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in product_tags[0:40]:\n",
    "    product=i.text\n",
    "    Sneaker_Description.append(product)    \n",
    "#scraping sneaker price from given wabpage      \n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:40]:\n",
    "    price=i.text\n",
    "    Sneaker_Price.append(price)    \n",
    "#scraping discount from given wabpage  \n",
    "discount_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "for i in discount_tags[0:40]:\n",
    "    discount=i.text\n",
    "    Sneaker_Discount.append(discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dcb2ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nevigating to the next page\n",
    "next_page=driver.find_element(By.XPATH,'//a[@class=\"ge-49M\"]')\n",
    "next_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a1d90105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 186 200 110\n"
     ]
    }
   ],
   "source": [
    "print(len(Sneaker_Brand),len(Sneaker_Description),len(Sneaker_Price),len(Sneaker_Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f1d65a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sneaker_Brand</th>\n",
       "      <th>Sneaker_Description</th>\n",
       "      <th>Sneaker_Price</th>\n",
       "      <th>Sneaker_Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RED CHIEF</td>\n",
       "      <td>RC3522 107 Sneakers For Men</td>\n",
       "      <td>₹2,294</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RED CHIEF</td>\n",
       "      <td>RC3483 022 Sneakers For Men</td>\n",
       "      <td>₹2,067</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹295</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kzaara</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹229</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>SM-671 Sneakers For Men</td>\n",
       "      <td>₹580</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Outdoor Trendy Lightweight Casual,Canvas Styli...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹459</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Caven Mid Sneakers For Men</td>\n",
       "      <td>₹489</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RED CHIEF</td>\n",
       "      <td>Perfect Stylish Casual Shoes For Girls &amp; Women...</td>\n",
       "      <td>₹2,294</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sneaker_Brand                                Sneaker_Description  \\\n",
       "0      RED CHIEF                        RC3522 107 Sneakers For Men   \n",
       "1      RED CHIEF                        RC3483 022 Sneakers For Men   \n",
       "2         Labbin                                   Sneakers For Men   \n",
       "3         Shozie                                   Sneakers For Men   \n",
       "4         Kzaara                                   Sneakers For Men   \n",
       "..           ...                                                ...   \n",
       "95      RapidBox                            SM-671 Sneakers For Men   \n",
       "96      ASTEROID  Outdoor Trendy Lightweight Casual,Canvas Styli...   \n",
       "97  Robbie jones                                   Sneakers For Men   \n",
       "98     Deals4you                         Caven Mid Sneakers For Men   \n",
       "99     RED CHIEF  Perfect Stylish Casual Shoes For Girls & Women...   \n",
       "\n",
       "   Sneaker_Price Sneaker_Discount  \n",
       "0         ₹2,294          55% off  \n",
       "1         ₹2,067          55% off  \n",
       "2           ₹399          60% off  \n",
       "3           ₹295          70% off  \n",
       "4           ₹229          77% off  \n",
       "..           ...              ...  \n",
       "95          ₹580          45% off  \n",
       "96          ₹499          75% off  \n",
       "97          ₹459          52% off  \n",
       "98          ₹489          80% off  \n",
       "99        ₹2,294          50% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Sneaker_Brand':Sneaker_Brand[0:100],'Sneaker_Description':Sneaker_Description[0:100],'Sneaker_Price':Sneaker_Price[0:100],'Sneaker_Discount':Sneaker_Discount[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e7c975",
   "metadata": {},
   "source": [
    "# Q7: Scrap the data of laptop from amazon.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "acfcf5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\user4\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user4\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user4\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "220bf06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException , NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dd53428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the driver....methos-1\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\User4\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f16a9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the website to driver\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb71d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty lists\n",
    "Laptop_title=[]\n",
    "Laptop_rating=[]\n",
    "Laptop_Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0cfe7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping the brand of laptop\n",
    "laptop_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in laptop_tags[0:10]:\n",
    "    title=i.text\n",
    "    Laptop_title.append(title)\n",
    "\n",
    "#scraping laptop rating from given wabpagea-size-medium a-color-base a-text-normal\n",
    "\n",
    "product_ratings=driver.find_elements(By.XPATH,'//span[@class=\"a-icon-alt\"]')\n",
    "for i in product_ratings[0:10]:\n",
    "    ratings=i.text\n",
    "    Laptop_rating.append(ratings)  \n",
    "\n",
    "#scraping laptop price from given wabpage      \n",
    "price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    laptopprice=i.text\n",
    "    Laptop_Price.append(laptopprice)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4e2dbd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 21 400\n"
     ]
    }
   ],
   "source": [
    "print(len(Laptop_title),len(Laptop_rating),len(Laptop_Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f903de8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop_title</th>\n",
       "      <th>Laptop_rating</th>\n",
       "      <th>Laptop_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td></td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Swift 5 Intel Evo Premium 14 Inches Full ...</td>\n",
       "      <td></td>\n",
       "      <td>1,05,385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Renewed) HP ProBook 430 G3 6th Gen Intel Core...</td>\n",
       "      <td></td>\n",
       "      <td>24,939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td></td>\n",
       "      <td>95,546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td></td>\n",
       "      <td>89,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS Zenbook 14 OLED (2022), 14\" (35.56 cms) 2...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Acer Nitro 5 Gaming Laptop/12th Gen Intel Core...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ASUS ZenBook Duo 14 (2021) Dual Screen Laptop,...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lenovo ThinkPad P14s Mobile Workstation 11th G...</td>\n",
       "      <td></td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td></td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(Renewed) Dell Precision Workstation Laptop M2...</td>\n",
       "      <td></td>\n",
       "      <td>1,49,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(Renewed) HP ProBook 430 G3 6th Gen Intel Core...</td>\n",
       "      <td></td>\n",
       "      <td>1,02,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td>1,02,038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GIGABYTE AORUS 5 SE4, 15.6” inch FHD 240Hz, In...</td>\n",
       "      <td></td>\n",
       "      <td>91,490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Laptop_title Laptop_rating  \\\n",
       "0   HP Pavilion x360 11th Gen Intel Core i7 14 inc...                 \n",
       "1   Acer Swift 5 Intel Evo Premium 14 Inches Full ...                 \n",
       "2   (Renewed) HP ProBook 430 G3 6th Gen Intel Core...                 \n",
       "3   HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...                 \n",
       "4   HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...                 \n",
       "5   Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...                 \n",
       "6   HP Pavilion x360 11th Gen Intel Core i7 14 inc...                 \n",
       "7   ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...                 \n",
       "8   ASUS Zenbook 14 OLED (2022), 14\" (35.56 cms) 2...                 \n",
       "9   Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...                 \n",
       "10  Acer Nitro 5 Gaming Laptop/12th Gen Intel Core...                 \n",
       "11  Lenovo ThinkBook 15 Intel 12th Gen Core i7 15....                 \n",
       "12  ASUS ZenBook Duo 14 (2021) Dual Screen Laptop,...                 \n",
       "13  Lenovo ThinkPad P14s Mobile Workstation 11th G...                 \n",
       "14  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...                 \n",
       "15  (Renewed) Dell Precision Workstation Laptop M2...                 \n",
       "16  (Renewed) HP ProBook 430 G3 6th Gen Intel Core...                 \n",
       "17  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...                 \n",
       "18  ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...                 \n",
       "19  GIGABYTE AORUS 5 SE4, 15.6” inch FHD 240Hz, In...                 \n",
       "\n",
       "   Laptop_Price  \n",
       "0        82,490  \n",
       "1      1,05,385  \n",
       "2        24,939  \n",
       "3        95,546  \n",
       "4        89,000  \n",
       "5                \n",
       "6                \n",
       "7                \n",
       "8                \n",
       "9                \n",
       "10               \n",
       "11               \n",
       "12               \n",
       "13       82,990  \n",
       "14       82,490  \n",
       "15     1,49,900  \n",
       "16     1,02,000  \n",
       "17       79,990  \n",
       "18     1,02,038  \n",
       "19       91,490  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Laptop_title':Laptop_title[0:20],'Laptop_rating':Laptop_rating[0:20],'Laptop_Price':Laptop_Price[0:20]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf1120",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1bffa4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the driver....methos-1\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\User4\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf7ed16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openig the naukari page on automated chrome browser\n",
    "driver.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21afe7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[1]\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4fcdbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quote_title=[]\n",
    "Author_Name=[]\n",
    "Type_quote=[]\n",
    "#scraping Quote title from given wabpage\n",
    "title_quote=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in title_quote[0:10]:\n",
    "    title=i.text\n",
    "    Quote_title.append(title)\n",
    "#scraping author name from given wabpage\n",
    "\n",
    "name_author=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in name_author[0:10]:\n",
    "    author=i.text\n",
    "    Author_Name.append(author)    \n",
    " #scraping type of quote from given wabpage\n",
    "quote_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in quote_tags[0:10]:\n",
    "    typequote=i.text\n",
    "    Type_quote.append(typequote)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0398f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quote_title=[]\n",
    "Author_Name=[]\n",
    "Type_quote=[]\n",
    "\n",
    "#scraping Quote title from given wabpage\n",
    "title_quote=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in title_quote[0:10]:\n",
    "    title=i.text\n",
    "    Quote_title.append(title)\n",
    "    \n",
    "#scraping author name from given wabpage\n",
    "\n",
    "name_author=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in name_author[0:10]:\n",
    "    author=i.text\n",
    "    Author_Name.append(author)\n",
    "    \n",
    "#scraping type of quote from given wabpage\n",
    "quote_tags=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in quote_tags[0:10]:\n",
    "    typequote=i.text\n",
    "    Type_quote.append(typequote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e49c042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Quote_title),len(Author_Name),len(Type_quote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9c6a9b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_title</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Type_quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Be more concerned with your character than you...</td>\n",
       "      <td>John Wooden</td>\n",
       "      <td>Inspirational, Success, Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Weak people revenge. Strong people forgive. In...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>Strong, Revenge, Intelligent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A mind is like a parachute. It doesn't work if...</td>\n",
       "      <td>Frank Zappa</td>\n",
       "      <td>Inspirational, Teacher, Religious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Never be afraid to raise your voice for honest...</td>\n",
       "      <td>William Faulkner</td>\n",
       "      <td>Truth, Honesty, Lying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>There are three kinds of men. The one that lea...</td>\n",
       "      <td>Will Rogers</td>\n",
       "      <td>Funny, Reading, Learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Quote_title         Author_Name  \\\n",
       "0  The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1  One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2  Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3  Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4  You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "5  Be more concerned with your character than you...         John Wooden   \n",
       "6  Weak people revenge. Strong people forgive. In...     Albert Einstein   \n",
       "7  A mind is like a parachute. It doesn't work if...         Frank Zappa   \n",
       "8  Never be afraid to raise your voice for honest...    William Faulkner   \n",
       "9  There are three kinds of men. The one that lea...         Will Rogers   \n",
       "\n",
       "                                 Type_quote  \n",
       "0  Essence, Deep Thought, Transcendentalism  \n",
       "1                 Inspiration, Past, Trying  \n",
       "2                       Country, Peace, War  \n",
       "3        Inspirational, Motivational, Death  \n",
       "4              4th Of July, Food, Patriotic  \n",
       "5        Inspirational, Success, Basketball  \n",
       "6              Strong, Revenge, Intelligent  \n",
       "7         Inspirational, Teacher, Religious  \n",
       "8                     Truth, Honesty, Lying  \n",
       "9                  Funny, Reading, Learning  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Quote_title':Quote_title,'Author_Name':Author_Name,'Type_quote':Type_quote})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddfefad",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,\n",
    "Term of office, Remarks) from https://www.jagranjosh.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b205045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the driver....methos-1\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\User4\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6f4a4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openig the naukari page on automated chrome browser\n",
    "driver.get(' https://www.jagranjosh.com/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fbc49832",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[1]\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4c360d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PM_Name=[]\n",
    "Born_dead=[]\n",
    "Term_office=[]\n",
    "Remarks=[]\n",
    "\n",
    "#scraping Name od Prime minister from given wabpage\n",
    "prime_name=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "for i in prime_name[0:10]:\n",
    "    name=i.text\n",
    "    PM_Name.append(name)\n",
    "    \n",
    "#scraping Born or dead from given wabpage\n",
    "\n",
    "prime_bord=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "for i in prime_bord[0:10]:\n",
    "    pmbord=i.text\n",
    "    Born_dead.append(pmbord)\n",
    "    \n",
    "#scraping term of office from given wabpage\n",
    "termof_office=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in termof_office[0:10]:\n",
    "    officeterm=i.text\n",
    "    Term_office.append(officeterm)\n",
    "\n",
    "#scraping remark from given wabpage\n",
    "pm_remark=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in pm_remark[0:10]:\n",
    "    pmremark=i.text\n",
    "    Remarks.append(pmremark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(PM_Name),len(Born_dead),len(Term_office),len(Remarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e12e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'PM_Name':PM_Name,'Born_dead':Born_dead,'Term_office':Term_office,'Remarks':Remarks})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434150bc",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e.\n",
    "Car name ,Description and Price) from https://www.motor1.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4187d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the driver....methos-1\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\User4\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7fcb00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openig the naukari page on automated chrome browser\n",
    "driver.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9898452",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[1]\")\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d90e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Car_Name=[]\n",
    "Car_description=[]\n",
    "Car_price=[]\n",
    "\n",
    "#scraping Car names from given wabpage\n",
    "car_name=driver.find_elements(By.XPATH,\"//h3[@class='subheader']\")\n",
    "for i in car_name[0:10]:\n",
    "    name=i.text\n",
    "    Car_Name.append(name)\n",
    "    \n",
    "#scraping car description from given wabpage\n",
    "\n",
    "description_car=driver.find_elements(By.XPATH,\"//p[@class='subheader']\")\n",
    "for i in description_car[0:10]:\n",
    "    description=i.text\n",
    "    Car_description.append(description)\n",
    "    \n",
    "#scraping car price from given wabpage\n",
    "price_car=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "for i in price_car[0:10]:\n",
    "    carprice=i.text\n",
    "    Car_price.append(carprice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=DUdvSxoaPlk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "673a65dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=108.0.5359.99)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x0098F243]\n\t(No symbol) [0x00917FD1]\n\t(No symbol) [0x0080D04D]\n\t(No symbol) [0x007F2D7A]\n\t(No symbol) [0x0085BE7B]\n\t(No symbol) [0x0086C196]\n\t(No symbol) [0x00858386]\n\t(No symbol) [0x0083163C]\n\t(No symbol) [0x0083269D]\n\tGetHandleVerifier [0x00C29A22+2655074]\n\tGetHandleVerifier [0x00C1CA24+2601828]\n\tGetHandleVerifier [0x00A38C0A+619850]\n\tGetHandleVerifier [0x00A37830+614768]\n\t(No symbol) [0x009205FC]\n\t(No symbol) [0x00925968]\n\t(No symbol) [0x00925A55]\n\t(No symbol) [0x0093051B]\n\tBaseThreadInitThunk [0x75396939+25]\n\tRtlGetFullPathName_UEx [0x77308FD2+1218]\n\tRtlGetFullPathName_UEx [0x77308F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16944/760768085.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#scraping Car names from given wabpage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcar_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"//h3[@class='subheader']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcar_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    890\u001b[0m         \u001b[1;31m# Return empty list if driver returns null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[1;31m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=108.0.5359.99)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x0098F243]\n\t(No symbol) [0x00917FD1]\n\t(No symbol) [0x0080D04D]\n\t(No symbol) [0x007F2D7A]\n\t(No symbol) [0x0085BE7B]\n\t(No symbol) [0x0086C196]\n\t(No symbol) [0x00858386]\n\t(No symbol) [0x0083163C]\n\t(No symbol) [0x0083269D]\n\tGetHandleVerifier [0x00C29A22+2655074]\n\tGetHandleVerifier [0x00C1CA24+2601828]\n\tGetHandleVerifier [0x00A38C0A+619850]\n\tGetHandleVerifier [0x00A37830+614768]\n\t(No symbol) [0x009205FC]\n\t(No symbol) [0x00925968]\n\t(No symbol) [0x00925A55]\n\t(No symbol) [0x0093051B]\n\tBaseThreadInitThunk [0x75396939+25]\n\tRtlGetFullPathName_UEx [0x77308FD2+1218]\n\tRtlGetFullPathName_UEx [0x77308F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "Car_Name=[]\n",
    "Car_description=[]\n",
    "Car_price=[]\n",
    "\n",
    "#scraping Car names from given wabpage\n",
    "car_name=driver.find_elements(By.XPATH,\"//h3[@class='subheader']\")\n",
    "for i in car_name[0:10]:\n",
    "    name=i.text\n",
    "    Car_Name.append(name)\n",
    "description_car=driver.find_elements(By.XPATH,\"//div[@class='m1_MobileMPU adgrid-ad-target']\")\n",
    "for i in description_car[0:10]:\n",
    "    description=i.text\n",
    "    Car_description.append(description)\n",
    "#scraping car price from given wabpage\n",
    "price_car=driver.find_elements(By.XPATH,\"//strong[@class='subheader']\")\n",
    "for i in price_car[0:10]:\n",
    "    carprice=i.text\n",
    "    Car_price.append(carprice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "acc63bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Car_Name),len(Car_description),len(Car_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d97f2abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Name</th>\n",
       "      <th>Car_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drako GTE</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Car_Name  Car_description\n",
       "0           Drako GTE                 \n",
       "1       De Tomaso P72                 \n",
       "2   Ferrari LaFerrari                 \n",
       "3       Pagani Huayra                 \n",
       "4        McLaren Elva                 \n",
       "5         Czinger 21C                 \n",
       "6       Ferrari Monza                 \n",
       "7  Gordon Murray T.33                 \n",
       "8   Koenigsegg Gemera                 \n",
       "9         Zenvo TSR-S                 "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Car_Name':Car_Name,' Car_description': Car_description})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7458a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
